{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ymlai\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from skimage.feature import hog\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the RGB channels separately\n",
    "    rhist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    ghist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    bhist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Generating bin centers\n",
    "    bin_edges = rhist[1]\n",
    "    bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((rhist[0], ghist[0], bhist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return rhist, ghist, bhist, bin_centers, hist_features\n",
    "\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    new_img = cv2.resize(img, size)\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = new_img.ravel() # Remove this line!\n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    if vis == True:\n",
    "        # Use skimage.hog() to get both features and a visualization\n",
    "        features, hog_image = hog(img, orientations=orient,\n",
    "                          pixels_per_cell=(pix_per_cell, pix_per_cell), \n",
    "                          cells_per_block=(cell_per_block, cell_per_block), \n",
    "                          transform_sqrt=False,\n",
    "                          visualise=True, feature_vector=False)\n",
    "                          \n",
    "        return features, hog_image\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient,\n",
    "                          pixels_per_cell=(pix_per_cell, pix_per_cell), \n",
    "                          cells_per_block=(cell_per_block, cell_per_block), \n",
    "                          transform_sqrt=False,\n",
    "                          visualise=False, feature_vector=feature_vec)\n",
    "                          \n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is your draw_boxes function from the previous exercise\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features_helper(feature_image, spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    file_features = []\n",
    "    \n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        file_features.append(spatial_features)\n",
    "    if hist_feat == True:\n",
    "        # Apply color_hist()\n",
    "        _,_,_,_,hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        file_features.append(hist_features)\n",
    "    if hog_feat == True:\n",
    "    # Call get_hog_features() with vis=False, feature_vec=True\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))\n",
    "            hog_features = np.ravel(hog_features)        \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        # Append the new feature vector to the features list\n",
    "        file_features.append(hog_features)\n",
    "    \n",
    "    return np.concatenate(file_features)\n",
    "    \n",
    "    \n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        \n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)   \n",
    "            \n",
    "        features.append(extract_features_helper(feature_image, spatial_size, \n",
    "                                                hist_bins, orient, pix_per_cell, cell_per_block, hog_channel,\n",
    "                                                spatial_feat, hist_feat, hog_feat))\n",
    "        \n",
    "        features.append(extract_features_helper(cv2.flip(feature_image, 1) , spatial_size, \n",
    "                                                hist_bins, orient, pix_per_cell, cell_per_block, hog_channel,\n",
    "                                                spatial_feat, hist_feat, hog_feat))\n",
    "        \n",
    "    # Return list of feature vectors\n",
    "    return features\n",
    "\n",
    "# Define a function to extract features from a single image window\n",
    "# This function is very similar to extract_features()\n",
    "# just for a single image rather than list of images\n",
    "def single_img_features(img, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):    \n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)      \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        _,_,_,_,hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))   \n",
    "            hog_features = np.ravel(hog_features) \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "# Define a function you will pass an image \n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, clf, scaler, color_space='RGB', \n",
    "                    spatial_size=(32, 32), hist_bins=32, \n",
    "                    hist_range=(0, 256), orient=9, \n",
    "                    pix_per_cell=8, cell_per_block=2, \n",
    "                    hog_channel=0, spatial_feat=True, \n",
    "                    hist_feat=True, hog_feat=True):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Linear SVC for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: 9 orientations 16 pixels per cell and 2 cells per block\n",
      "Feature vector length: 4140\n",
      "Car example:  5966\n",
      "Non car example:  8968\n"
     ]
    }
   ],
   "source": [
    "# Read in cars and notcars\n",
    "images = glob.glob('./vehicle_dataset/*.jpeg')\n",
    "cars = []\n",
    "notcars = []\n",
    "for image in images:\n",
    "    if 'image' in image or 'extra' in image:\n",
    "        notcars.append(image)\n",
    "    else:\n",
    "        cars.append(image)\n",
    "\n",
    "### TODO: Tweak these parameters and see how the results change.\n",
    "color_space = 'YCrCb' # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 16 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = \"ALL\" # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (32, 32) # Spatial binning dimensions\n",
    "hist_bins = 32    # Number of histogram bins\n",
    "spatial_feat = True # Spatial features on or off\n",
    "hist_feat = True # Histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "y_start_stop = [400, 656] # Min and max in y to search in slide_window()\n",
    "\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                        orient=orient, pix_per_cell=pix_per_cell, \n",
    "                        cell_per_block=cell_per_block, \n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "\n",
    "car_features = [x.astype(np.float64) for x in car_features]\n",
    "notcar_features = [x.astype(np.float64) for x in notcar_features]\n",
    "\n",
    "X = np.vstack((np.array(car_features), np.array(notcar_features))).astype(np.float64)          \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "print('Car example: ', len(cars))\n",
    "print('Non car example: ', len(notcars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.49 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.998\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print('Test Accuracy of SVC = ', round(sklearn.metrics.accuracy_score(y_test, y_pred), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of incorrectly classified images: 12\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAFbCAYAAAAa1w+vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x218f7189588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification analysis\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "wrong_pred = X_test[y_test != y_pred]\n",
    "print(\"Number of incorrectly classified images: %d\" % len(wrong_pred))\n",
    "cnf_matrix = sklearn.metrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plot_confusion_matrix(cnf_matrix, classes=['car', 'not car'], normalize=False,\n",
    "                      title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching for cars 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from itertools import product\n",
    "\n",
    "def window_searching(ctrans_tosearch, hog1, hog2, hog3, ystart, xb, yb, cells_per_step, \n",
    "                     nblocks_per_window, pix_per_cell, window, scale, X_scaler, svc):\n",
    "    ypos = yb*cells_per_step\n",
    "    xpos = xb*cells_per_step\n",
    "    \n",
    "    xleft = xpos*pix_per_cell\n",
    "    ytop = ypos*pix_per_cell\n",
    "\n",
    "    # Extract the image patch\n",
    "    subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "    \n",
    "    # Extract HOG for this patch\n",
    "    hog_feat_list = [None, None, None]\n",
    "    if hog_channel == 'ALL':\n",
    "        hog_feat_list[0] = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "        hog_feat_list[1] = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "        hog_feat_list[2] = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "        hog_features = np.hstack((hog_feat_list[0], hog_feat_list[1], hog_feat_list[2]))\n",
    "    else:\n",
    "        hog_features = hog_feature[hog_channel]\n",
    "\n",
    "    # Get color features\n",
    "    spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "    _,_,_,_,hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "    img_features = []\n",
    "    if spatial_feat == True:\n",
    "        img_features.append(spatial_features)\n",
    "    if hist_feat == True:\n",
    "        img_features.append(hist_features)\n",
    "    if hog_feat == True:\n",
    "        img_features.append(hog_features)\n",
    "\n",
    "    # Scale features and make a prediction\n",
    "    test_features = X_scaler.transform(np.hstack(img_features).reshape(1, -1))   \n",
    "    test_prediction = svc.predict(test_features)\n",
    "\n",
    "    ## testing only\n",
    "    #xbox_left = np.int(xleft*scale)\n",
    "    #ytop_draw = np.int(ytop*scale)\n",
    "    #win_draw = np.int(window*scale)\n",
    "    #box_list.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "    xbox_left = np.int(xleft*scale)\n",
    "    ytop_draw = np.int(ytop*scale)\n",
    "    win_draw = np.int(window*scale)\n",
    "    \n",
    "    if test_prediction == 1:\n",
    "        return ((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart))\n",
    "    else:\n",
    "        return None\n",
    "        #return ((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart))\n",
    "\n",
    "\n",
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, color_space, ystart, ystop, scale, svc, X_scaler, \n",
    "              orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, hog_channel='ALL', \n",
    "              spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    \n",
    "    draw_img = np.copy(img)\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YCrCb)\n",
    "    else: ctrans_tosearch = np.copy(img)      \n",
    "    \n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "    \n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    \n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "    cells_per_step =1 #2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "\n",
    "    box_list = []\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            box_list.append(window_searching(ctrans_tosearch, hog1, hog2, hog3, ystart, xb, yb, cells_per_step, \n",
    "                     nblocks_per_window, pix_per_cell, window, scale, X_scaler, svc)) \n",
    "        \n",
    "    box_list = [box for box in box_list if box !=None]\n",
    "    for box in box_list:\n",
    "        cv2.rectangle(draw_img,box[0],box[1],(0,0,255),6) \n",
    "                \n",
    "    return draw_img, box_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling false postive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "# Read in image similar to one shown above \n",
    "#image = mpimg.imread('./notebook_images/test_image.png')\n",
    "image = mpimg.imread('./notebook_images/bbox-example-image.jpg')\n",
    "\n",
    "heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "def add_heat(heatmap, bbox_list, bbox_list_w):\n",
    "    # Iterate through list of bboxes\n",
    "    for box, w in zip(bbox_list, bbox_list_w):\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += w\n",
    "\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "frame_cnt= 0\n",
    "global_box_list = []\n",
    "global_box_list_w = []\n",
    "\n",
    "def pipeline(debug, img):\n",
    "    global frame_cnt\n",
    "    global global_box_list\n",
    "    global global_box_list_w\n",
    "    \n",
    "    frame_cnt += 1\n",
    "    scale = 1  #1.5\n",
    "\n",
    "    if len(global_box_list_w) > 0:\n",
    "        global_box_list_w = [ x * 0.5 for x in global_box_list_w ]\n",
    "\n",
    "        global_box_list = [global_box_list[i] for i in range(len(global_box_list_w)) if global_box_list_w[i] >= 0.1] \n",
    "        global_box_list_w = [global_box_list_w[i] for i in range(len(global_box_list_w)) if global_box_list_w[i] >= 0.1]\n",
    "    \n",
    "    out_img, box_list = find_cars(img, color_space, y_start_stop[0], y_start_stop[1], \n",
    "                                  scale, svc, X_scaler, orient, pix_per_cell, cell_per_block, \n",
    "                                  spatial_size, hist_bins, hog_channel, \n",
    "                                  spatial_feat, hist_feat, hog_feat\n",
    "                                 )\n",
    "    \n",
    "    \n",
    "    global_box_list.extend(box_list)\n",
    "    global_box_list_w.extend(np.repeat(1, len(box_list)))\n",
    "    \n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    \n",
    "    heat = add_heat(heat, global_box_list, global_box_list_w)\n",
    "\n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,2)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    #draw_img = draw_boxes(np.copy(img), box_list, color=(0, 0, 255), thick=2)\n",
    "    \n",
    "    if debug:\n",
    "        debug_im = Image.new('RGB', (image.shape[1] * 3 // 2, image.shape[0]))\n",
    "        cv2.putText(draw_img, \"Frame: %d\" % frame_cnt, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2,\n",
    "                    cv2.LINE_AA)\n",
    "        debug_im.paste(Image.fromarray(draw_img), (0, 0))\n",
    "        debug_im.paste(Image.fromarray(cv2.resize(out_img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_CUBIC)),\n",
    "                (image.shape[1], 0))\n",
    "        heatmap = cv2.merge([heatmap/np.max(heatmap)*255, np.zeros_like(heatmap), np.zeros_like(heatmap)]).astype(np.uint8)\n",
    "        debug_im.paste(Image.fromarray(cv2.resize(heatmap, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_CUBIC)),\n",
    "                (image.shape[1],  image.shape[0] // 2))\n",
    "        \n",
    "        return np.array(debug_im)\n",
    "    else:\n",
    "        return draw_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle detection pipeline on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "t_images = glob.glob('./test_images/*.*')\n",
    "\n",
    "for i, fname in enumerate(t_images):    \n",
    "    image = mpimg.imread(fname)\n",
    "    image = image[:,:,0:3]\n",
    "    frame_cnt= 0\n",
    "    global_box_list = []\n",
    "    global_box_list_w = []\n",
    "\n",
    "    draw_img = pipeline(False, image)\n",
    "    plt.imsave(os.path.join('./output_images', os.path.basename(fname)), draw_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xxxx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-5d29f8b01191>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mxxxx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'xxxx' is not defined"
     ]
    }
   ],
   "source": [
    "xxxx.dd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle detection pipeline on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(debug, image):\n",
    "\n",
    "    draw_img = pipeline(debug, image)\n",
    "\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_video_output.mp4\n",
      "[MoviePy] Writing video test_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▉  | 38/39 [00:36<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_video_output.mp4 \n",
      "\n",
      "Wall time: 37.5 s\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "clip1 = VideoFileClip(\"test_video.mp4\")\n",
    "clip1_output = \"test_video_output.mp4\"\n",
    "\n",
    "frame_cnt = 0\n",
    "global_box_list = []\n",
    "global_box_list_w = []\n",
    "    \n",
    "test_clip = clip1.fl_image(partial(process_image, True) ) \n",
    "%time test_clip.write_videofile(clip1_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video project_video_output.mp4\n",
      "[MoviePy] Writing video project_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [26:06<00:01,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: project_video_output.mp4 \n",
      "\n",
      "Wall time: 26min 7s\n"
     ]
    }
   ],
   "source": [
    "clip2 = VideoFileClip(\"project_video.mp4\")\n",
    "clip2_output = \"project_video_output.mp4\"\n",
    "\n",
    "\n",
    "frame_cnt = 0\n",
    "global_box_list = []\n",
    "global_box_list_w = []\n",
    "\n",
    "project_clip = clip2.fl_image(partial(process_image, True)) \n",
    "%time project_clip.write_videofile(clip2_output, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "save_object = { \"svc\": svc, \"scaler\": X_scaler, \n",
    "                  \"orient\": orient, \"pix_per_cell\": pix_per_cell, \"cell_per_block\": cell_per_block,\n",
    "                  \"spatial_size\": spatial_size, \"hist_bins\": hist_bins,\n",
    "                   \"y_start_stop\": y_start_stop, \"color_space\": color_space,\n",
    "                   \"hog_channel\": hog_channel, \"spatial_feat\": spatial_feat,\n",
    "                   \"hist_feat\": hist_feat, \"hog_feat\": hog_feat\n",
    "                 }\n",
    "\n",
    "pickle.dump( save_object, open( \"svc_pickle_final.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = plt.imread('vehicle_dataset/1000.jpeg')\n",
    "plt.imshow(test_img)\n",
    "\n",
    "car_features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print(svc.predict(X_scaler.transform(np.array(car_features).reshape(1, -1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test - incorrect case\n",
    "test_img = plt.imread('vehicle_dataset/image1605.jpeg')\n",
    "plt.imshow(test_img)\n",
    "\n",
    "not_car_features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print(svc.predict(X_scaler.transform(np.array(not_car_features).reshape(1, -1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = plt.imread('test_images/test1.jpg')\n",
    "#1043 373 => 1187 517\n",
    "test_img = cv2.resize(image[373:517, 1043:1187], (64, 64))  \n",
    "plt.imshow(test_img)\n",
    "\n",
    "car_features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print(svc.predict(X_scaler.transform(np.array(car_features).reshape(1, -1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = cv2.resize(image[500:644, 503:647], (64, 64))  \n",
    "plt.imshow(test_img)\n",
    "\n",
    "car_features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print(svc.predict(X_scaler.transform(np.array(car_features).reshape(1, -1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
