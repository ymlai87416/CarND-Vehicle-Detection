{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ymlai\\Anaconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "from skimage.feature import hog\n",
    "from scipy.ndimage.measurements import label\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VehicleDetector:\n",
    "    \n",
    "\n",
    "    def __init__(self):\n",
    "        dist_pickle = pickle.load( open(\"svc_pickle_final.p\", \"rb\" ) )\n",
    "        self.svc = dist_pickle[\"svc\"]\n",
    "        self.X_scaler = dist_pickle[\"scaler\"]\n",
    "        self.orient = dist_pickle[\"orient\"]\n",
    "        self.pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "        self.cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "        self.spatial_size = dist_pickle[\"spatial_size\"]\n",
    "        self.hist_bins = dist_pickle[\"hist_bins\"]\n",
    "        self.y_start_stop = dist_pickle[\"y_start_stop\"]\n",
    "        self.color_space = dist_pickle[\"color_space\"]\n",
    "        self.hog_channel = dist_pickle[\"hog_channel\"]\n",
    "        self.spatial_feat = dist_pickle[\"spatial_feat\"]\n",
    "        self.hist_feat = dist_pickle[\"hist_feat\"]\n",
    "        self.hog_feat = dist_pickle[\"hog_feat\"]\n",
    "        \n",
    "        self.frame_cnt = 0\n",
    "        self.global_box_list = []\n",
    "        self.global_box_list_w = []\n",
    "        self.heat_threshold = 2\n",
    "        self.heat_decay = 0.5\n",
    "        self.scale = 1.5\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        self.frame_cnt = 0\n",
    "        self.global_box_list = []\n",
    "        self.global_box_list_w = []\n",
    "        \n",
    "    def color_hist(self, img, nbins=32, bins_range=(0, 256)):\n",
    "        # Compute the histogram of the RGB channels separately\n",
    "        rhist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "        ghist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "        bhist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "        # Generating bin centers\n",
    "        bin_edges = rhist[1]\n",
    "        bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "        # Concatenate the histograms into a single feature vector\n",
    "        hist_features = np.concatenate((rhist[0], ghist[0], bhist[0]))\n",
    "        # Return the individual histograms, bin_centers and feature vector\n",
    "        return rhist, ghist, bhist, bin_centers, hist_features\n",
    "\n",
    "    def bin_spatial(self, img, size=(32, 32)):\n",
    "        new_img = cv2.resize(img, size)\n",
    "        # Use cv2.resize().ravel() to create the feature vector\n",
    "        features = new_img.ravel() # Remove this line!\n",
    "        # Return the feature vector\n",
    "        return features\n",
    "\n",
    "    # Define a function to return HOG features and visualization\n",
    "    def get_hog_features(self, img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "        if vis == True:\n",
    "            # Use skimage.hog() to get both features and a visualization\n",
    "            features, hog_image = hog(img, orientations=orient,\n",
    "                              pixels_per_cell=(pix_per_cell, pix_per_cell), \n",
    "                              cells_per_block=(cell_per_block, cell_per_block), \n",
    "                              transform_sqrt=False,\n",
    "                              visualise=True, feature_vector=False)\n",
    "                              \n",
    "            return features, hog_image\n",
    "        else:      \n",
    "            features = hog(img, orientations=orient,\n",
    "                              pixels_per_cell=(pix_per_cell, pix_per_cell), \n",
    "                              cells_per_block=(cell_per_block, cell_per_block), \n",
    "                              transform_sqrt=False,\n",
    "                              visualise=False, feature_vector=feature_vec)\n",
    "                              \n",
    "            return features\n",
    "    \n",
    "    # Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "    def find_cars(self, img, color_space, ystart, ystop, scale, svc, X_scaler, \n",
    "                  orient, pix_per_cell, cell_per_block, spatial_size, hist_bins, hog_channel='ALL', \n",
    "                  spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "        \n",
    "        draw_img = np.copy(img)\n",
    "        \n",
    "        img_tosearch = img[ystart:ystop,:,:]\n",
    "\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YCrCb)\n",
    "        else: ctrans_tosearch = np.copy(img)      \n",
    "        \n",
    "        img = img.astype(np.float32)/255\n",
    "        \n",
    "        if scale != 1:\n",
    "            imshape = ctrans_tosearch.shape\n",
    "            ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "            \n",
    "        ch1 = ctrans_tosearch[:,:,0]\n",
    "        ch2 = ctrans_tosearch[:,:,1]\n",
    "        ch3 = ctrans_tosearch[:,:,2]\n",
    "        \n",
    "        # Define blocks and steps as above\n",
    "        nxblocks = (ch1.shape[1] // pix_per_cell) - cell_per_block + 1\n",
    "        nyblocks = (ch1.shape[0] // pix_per_cell) - cell_per_block + 1 \n",
    "        nfeat_per_block = orient*cell_per_block**2\n",
    "        \n",
    "        # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "        window = 64\n",
    "        nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "        cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step + 1\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step + 1\n",
    "        \n",
    "        # Compute individual channel HOG features for the entire image\n",
    "        hog1 = self.get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog2 = self.get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog3 = self.get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        \n",
    "        box_list = []\n",
    "        \n",
    "        for xb in range(nxsteps):\n",
    "            for yb in range(nysteps):\n",
    "                ypos = yb*cells_per_step\n",
    "                xpos = xb*cells_per_step\n",
    "                # Extract HOG for this patch\n",
    "                hog_feat_list = [None, None, None]\n",
    "                if hog_channel == 'ALL':\n",
    "                    hog_feat_list[0] = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    hog_feat_list[1] = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    hog_feat_list[2] = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].ravel() \n",
    "                    hog_features = np.hstack((hog_feat_list[0], hog_feat_list[1], hog_feat_list[2]))\n",
    "                else:\n",
    "                    hog_features = hog_feature[hog_channel]\n",
    "\n",
    "                xleft = xpos*pix_per_cell\n",
    "                ytop = ypos*pix_per_cell\n",
    "\n",
    "                # Extract the image patch\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop+window, xleft:xleft+window], (64,64))\n",
    "              \n",
    "                # Get color features\n",
    "                spatial_features = self.bin_spatial(subimg, size=spatial_size)\n",
    "                _,_,_,_,hist_features = self.color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "                img_features = []\n",
    "                if spatial_feat == True:\n",
    "                    img_features.append(spatial_features)\n",
    "                if hist_feat == True:\n",
    "                    img_features.append(hist_features)\n",
    "                if hog_feat == True:\n",
    "                    img_features.append(hog_features)\n",
    "                \n",
    "                # Scale features and make a prediction\n",
    "                test_features = X_scaler.transform(np.hstack(img_features).reshape(1, -1))   \n",
    "                test_prediction = svc.predict(test_features)\n",
    "                \n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft*scale)\n",
    "                    ytop_draw = np.int(ytop*scale)\n",
    "                    win_draw = np.int(window*scale)\n",
    "                    cv2.rectangle(draw_img,(xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart),(0,0,255),6) \n",
    "                    box_list.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "                    \n",
    "        return draw_img, box_list\n",
    "\n",
    "    def add_heat(self, heatmap, bbox_list, bbox_list_w):\n",
    "        # Iterate through list of bboxes\n",
    "        for box, w in zip(bbox_list, bbox_list_w):\n",
    "            # Add += 1 for all pixels inside each bbox\n",
    "            # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "            heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += w\n",
    "\n",
    "        # Return updated heatmap\n",
    "        return heatmap# Iterate through list of bboxes\n",
    "        \n",
    "    def apply_threshold(self, heatmap, threshold):\n",
    "        # Zero out pixels below the threshold\n",
    "        heatmap[heatmap <= threshold] = 0\n",
    "        # Return thresholded map\n",
    "        return heatmap\n",
    "\n",
    "    def draw_labeled_bboxes(self, img, labels):\n",
    "        # Iterate through all detected cars\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "        # Return the image\n",
    "        return img\n",
    "    \n",
    "    def detect_vehicle(self, image):\n",
    "        self.frame_cnt += 1\n",
    "\n",
    "        if len(self.global_box_list_w) > 0:\n",
    "            self.global_box_list_w = [ x * self.heat_decay for x in self.global_box_list_w ]\n",
    "\n",
    "            self.global_box_list = [self.global_box_list[i] for i in range(len(self.global_box_list_w)) if self.global_box_list_w[i] >= 0.1] \n",
    "            self.global_box_list_w = [self.global_box_list_w[i] for i in range(len(self.global_box_list_w)) if self.global_box_list_w[i] >= 0.1]\n",
    "        \n",
    "        out_img, box_list = self.find_cars(image, self.color_space, self.y_start_stop[0], self.y_start_stop[1], \n",
    "                                      self.scale, self.svc, self.X_scaler, self.orient, self.pix_per_cell, self.cell_per_block, \n",
    "                                      self.spatial_size, self.hist_bins, self.hog_channel, \n",
    "                                      self.spatial_feat, self.hist_feat, self.hog_feat\n",
    "                                     )\n",
    "        \n",
    "        \n",
    "        self.global_box_list.extend(box_list)\n",
    "        self.global_box_list_w.extend(np.repeat(1, len(box_list)))\n",
    "        \n",
    "        heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "        \n",
    "        heat = self.add_heat(heat, self.global_box_list, self.global_box_list_w)\n",
    "\n",
    "        # Apply threshold to help remove false positives\n",
    "        heat = self.apply_threshold(heat, self.heat_threshold)\n",
    "\n",
    "        # Visualize the heatmap when displaying    \n",
    "        heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "        # Find final boxes from heatmap using label function\n",
    "        labels = label(heatmap)\n",
    "        \n",
    "        \n",
    "        return labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_detector = None\n",
    "\n",
    "def process_image(debug, image):\n",
    "    global vehicle_detector\n",
    "    labels = vehicle_detector.detect_vehicle(image)\n",
    "    draw_img = vehicle_detector.draw_labeled_bboxes(np.copy(image), labels)\n",
    "\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video test_video_output.mp4\n",
      "[MoviePy] Writing video test_video_output.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|███████████████████████████████████████████████████████████████████████████████▉  | 38/39 [00:23<00:00,  1.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: test_video_output.mp4 \n",
      "\n",
      "Wall time: 23.9 s\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "vehicle_detector = VehicleDetector()\n",
    "\n",
    "\n",
    "clip1 = VideoFileClip(\"test_video.mp4\")\n",
    "clip1_output = \"test_video_output.mp4\"\n",
    "    \n",
    "test_clip = clip1.fl_image(partial(process_image, True) ) \n",
    "%time test_clip.write_videofile(clip1_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "dist_pickle = pickle.load( open(\"svc_pickle_final.p\", \"rb\" ) )\n",
    "svc = dist_pickle[\"svc\"]\n",
    "X_scaler = dist_pickle[\"scaler\"]\n",
    "orient = dist_pickle[\"orient\"]\n",
    "pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "spatial_size = dist_pickle[\"spatial_size\"]\n",
    "hist_bins = dist_pickle[\"hist_bins\"]\n",
    "\n",
    "save_object = { \"svc\": svc, \"scaler\": X_scaler, \n",
    "                  \"orient\": orient, \"pix_per_cell\": pix_per_cell, \"cell_per_block\": cell_per_block,\n",
    "                  \"spatial_size\": spatial_size, \"hist_bins\": hist_bins,\n",
    "                   \"y_start_stop\": [400, 656], \"color_space\": 'YCrCb',\n",
    "                   \"hog_channel\": 'ALL', \"spatial_feat\": True,\n",
    "                   \"hist_feat\": True, \"hog_feat\": True\n",
    "                 }\n",
    "\n",
    "pickle.dump( save_object, open( \"svc_pickle_final.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
